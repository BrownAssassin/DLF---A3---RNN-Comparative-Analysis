{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports & Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colours:\n",
    "    HEADER = '\\033[95m'     # Miscellaneous\n",
    "    BLUE = '\\033[94m'       # Hyperparameters\n",
    "    GREEN = '\\033[92m'      # Accuracies\n",
    "    RED = '\\033[91m'        # Loss\n",
    "    ENDC = '\\033[0m'        # End Colours\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: \u001b[95mcuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {Colours.HEADER}{device}{Colours.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Optuna verbosity to see detailed output for every trial\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_data = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "test_data = pd.read_csv('Google_Stock_Price_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample after Scaling:\n",
      "       Open      High       Low     Close    Volume\n",
      "0  0.085814  0.096401  0.090449  0.237573  0.295258\n",
      "1  0.097012  0.098344  0.098235  0.241514  0.229936\n",
      "2  0.094334  0.092517  0.094086  0.228781  0.263612\n",
      "3  0.091562  0.088819  0.088006  0.216419  0.216179\n",
      "4  0.079842  0.076718  0.061070  0.178548  0.467797\n",
      "\n",
      "Validation Data Sample after Scaling:\n",
      "          Open      High       Low     Close    Volume\n",
      "1006  0.862936  0.864381  0.860055  0.345410  0.130753\n",
      "1007  0.869354  0.879209  0.874034  0.346430  0.077805\n",
      "1008  0.838753  0.870207  0.855622  0.347863  0.077657\n",
      "1009  0.839330  0.853997  0.836945  0.324118  0.118374\n",
      "1010  0.841450  0.844156  0.825466  0.307691  0.097837\n"
     ]
    }
   ],
   "source": [
    "# Convert columns to numeric by removing commas explicitly\n",
    "for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "    # Convert to string, remove commas, and convert to float\n",
    "    train_data[col] = train_data[col].astype(str).str.replace(',', '').astype(float)\n",
    "    test_data[col] = test_data[col].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Drop the 'Date' column for training, as it's not needed\n",
    "train_data = train_data.drop(['Date'], axis=1)\n",
    "test_data = test_data.drop(['Date'], axis=1)\n",
    "\n",
    "# Normalize the features to bring them in the range [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "\n",
    "# Convert scaled_train_data to DataFrame for easier handling\n",
    "scaled_train_df = pd.DataFrame(scaled_train_data, columns=train_data.columns)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_df, val_df = train_test_split(scaled_train_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(\"\\nTraining Data Sample after Scaling:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nValidation Data Sample after Scaling:\")\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X_train shape: torch.Size([976, 30, 5]), y_train shape: torch.Size([976])\n",
      "Validation set: X_val shape: torch.Size([222, 30, 5]), y_val shape: torch.Size([222])\n",
      "Testing set: X_test shape: torch.Size([10, 10, 5]), y_test shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Function to create sequences using PyTorch tensors\n",
    "def create_sequences_torch(data, sequence_length, device):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data.iloc[i:i + sequence_length].values)   # Features over the sequence length\n",
    "        y.append(data['Close'].iloc[i + sequence_length])   # Target value (Close price)\n",
    "\n",
    "    # Convert lists to NumPy arrays and then to PyTorch tensors\n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(np.array(y), dtype=torch.float32).to(device)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Define the sequence length for the training and validation sets\n",
    "sequence_length = 30    # Using 30 days to predict the next day's price\n",
    "\n",
    "# Create sequences for training and validation using the defined sequence length\n",
    "X_train, y_train = create_sequences_torch(train_df, sequence_length, device)\n",
    "X_val, y_val = create_sequences_torch(val_df, sequence_length, device)\n",
    "\n",
    "# Use a smaller sequence length for the testing set (10 days)\n",
    "test_sequence_length = 10\n",
    "X_test, y_test = create_sequences_torch(pd.DataFrame(scaled_test_data, columns=train_data.columns), test_sequence_length, device)\n",
    "\n",
    "# Display the shape of the created sequences\n",
    "print(f\"Training set: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"Validation set: X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"Testing set: X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN) Architecture Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
